# -*- coding: utf-8 -*-
"""AI Research Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZLLMNHyQbhs0syYmx-b787rp5sJNmB0D
"""

!pip install ucimlrepo
from ucimlrepo import fetch_ucirepo

# fetch dataset
bank_marketing = fetch_ucirepo(id=222)

# data (as pandas dataframes)
X = bank_marketing.data.features
y = bank_marketing.data.targets

# metadata
print(bank_marketing.metadata)

# variable information
print(bank_marketing.variables)

print(y)

print(y)

from pycaret.classification import *
import pandas as pd
categorical_columns = X.select_dtypes(include=['object']).columns
X_encoded = pd.get_dummies(X, columns=categorical_columns)
X_encoded.rename(columns={"job_admin." : "job_admin"}, inplace=True)
print(X_encoded)
s = setup(X_encoded, target = y, session_id = 123)

from pycaret.classification import ClassificationExperiment


exp = ClassificationExperiment()
type(exp)

exp.setup(X_encoded, target = y, session_id = 123)

best = compare_models()

exp.compare_models()

plot_model(best, plot = 'confusion_matrix')

plot_model(best, plot = 'auc')

plot_model(best, plot = 'feature')

help(plot_model)

evaluate_model(best)

holdout_pred = predict_model(best)

holdout_pred.head()

new_data = X_encoded.copy()


new_data.head()

predictions = predict_model(best, data = new_data)

predictions.head()

save_model(best, 'bank_pipeline')

loaded_best_pipeline = load_model('bank_pipeline')
loaded_best_pipeline

s = setup(X_encoded, target = y, session_id = 123)

get_config()

get_config('X_train_transformed')

print("The current seed is: {}".format(get_config('seed')))

set_config('seed', 786)
print("The new seed is: {}".format(get_config('seed')))

s = setup(X_encoded, target = y, session_id = 123,
          normalize = True, normalize_method = 'minmax')

get_config('X_train_transformed')['age'].hist()

get_config('X_train')['balance'].hist()

import matplotlib.pyplot as plt
plt.hist(get_config('X_train_transformed')['balance'], edgecolor='black', range=[0, 15000])

plt.hist(get_config('X_train')['balance'], edgecolor='black', range=[0, 15000])

plt.hist(get_config('X_train_transformed')['duration'], edgecolor='black', range=[0, 2000])

plt.hist(get_config('X_train')['balance'], edgecolor='black', range=[0, 2000])

best = compare_models()

models()

compare_tree_models = compare_models(include = ['dt', 'rf', 'et', 'gbc', 'xgboost', 'lightgbm', 'catboost'])

compare_tree_models

compare_tree_models_results = pull()
compare_tree_models_results

best_recall_models_top3 = compare_models(sort = 'Recall', n_select = 3)

best_recall_models_top3

models()

lr = create_model('lr')

lr_results = pull()
print(type(lr_results))
lr_results

lr = create_model('lr', fold=3)

create_model('lr', C = 0.5, l1_ratio = 0.15)

create_model('lr', return_train_score=True)

dt = create_model('dt')

tuned_dt = tune_model(dt)

dt

dt_grid = {'max_depth' : [None, 2, 4, 6, 8, 10, 12]}
tuned_dt = tune_model(dt, custom_grid = dt_grid, optimize = 'F1')

tuned_dt, tuner = tune_model(dt, return_tuner=True)

tuned_dt

tuner

tuned_dt = tune_model(dt, search_library = 'optuna')

ensemble_model(dt, method = 'Bagging')

ensemble_model(dt, method = 'Boosting')

best_recall_models_top3

blend_models(best_recall_models_top3)

stack_models(best_recall_models_top3)

plot_model(best, plot = 'class_report')

plot_model(best, plot = 'class_report', scale = 2)

plot_model(best, plot = 'class_report', save=True)

lightgbm = create_model('lightgbm')

interpret_model(lightgbm, plot = 'summary')

interpret_model(lightgbm, plot = 'reason', observation = 1)

lb = get_leaderboard()
lb

lb.sort_values(by='F1', ascending=False)['Model'].iloc[0]

automl()

dashboard(dt, display_format ='inline')

!pip install gradio

create_app(best)

create_api(best, api_name = 'bank_api')

create_docker('bank_api')

final_best = finalize_model(best)

final_best

print(convert_model(dt, language = 'java'))

save_model(best, 'bank_model')

loaded_from_disk = load_model('bank_model')
loaded_from_disk

save_experiment('bank_experiment')

exp_from_disk = load_experiment('bank_experiment', data=X_encoded)

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

categorical_columns = X.select_dtypes(include=['object']).columns
X_encoded = pd.get_dummies(X, columns=categorical_columns)

X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

# Create a Random Forest Classifier
clf = RandomForestClassifier(random_state=42)

# Fit the classifier to the training data
clf.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = clf.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

# Display classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))